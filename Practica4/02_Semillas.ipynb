{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "539ea13f",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Se desea utilizar una red multiperceptrón para reconocer muestras de tres variedades diferentes de trigo:  Kama, Rosa y Canadiense. Para entrenarla se utilizará una parte de los ejemplos del archivo **SEMILLAS.CSV**.  \n",
    "\n",
    "Fuente de datos: **Seeds Data Set** - https://archive.ics.uci.edu/ml/datasets/seeds  \n",
    "\n",
    "### a)\n",
    "\n",
    "Con respecto a la arquitectura, indique:  \n",
    "\n",
    "- La cantidad de neuronas de la capa de entrada.  \n",
    "- La cantidad de neuronas de la capa de salida.  \n",
    "- La cantidad de pesos (arcos) que tiene la red si se utiliza una única capa oculta formada por 4 neuronas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccf1ac1",
   "metadata": {},
   "source": [
    "- Tenemos 6 neuronas en la capa de entrada\n",
    "- Tenemos 3 Neuronas en la capa de salida\n",
    "- Tenemos $6*4 + 4*3 = 36$ Pesos \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ea4ce",
   "metadata": {},
   "source": [
    "### b)\n",
    "\n",
    "La arquitectura del multiperceptrón utilizado para predecir los 3 tipos de semillas está formada por 3 capas: la capa de entrada, una única capa oculta de 4 neuronas y la capa de salida. Las funciones de activación para las capas oculta y de salida son “tanh” y “sigmoid” respectivamente. Indique cuáles de los siguientes factores inciden en la dirección de cambio (signo de la modificación) de los pesos de la red:  \n",
    "\n",
    "- El error cometido en la predicción.  \n",
    "- El valor de la derivada de la función de activación.  \n",
    "- Los valores anteriores de los pesos de la red.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8524ab86",
   "metadata": {},
   "source": [
    "Todas influyen en la modificacion de los pesos de la red, ya que el error cometido se utiliza para verificar si el mismo cumple o no la COTA provista, el valor de la derivada de la funcion de activacion se utiliza en la formula para modificar los pesos entre capas y a la salida, y los valores anteriores del peso de la red se utilizan directamente para calcular la siguiente iteracion de los mismos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e545b076",
   "metadata": {},
   "source": [
    "### c)\n",
    "\n",
    "Luego de ingresar una muestra de semilla a la red se obtiene como salida (0.78, 0, 0). Utilizando la arquitectura descripta en b), indique cuántos pesos de la red serán modificados sabiendo que la respuesta esperada es (1, 0, 0).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db51bfdc",
   "metadata": {},
   "source": [
    "Durante backpropagation, los pesos que se actualizan dependen del gradiente de error de cada neurona de salida.\n",
    "\n",
    "Neurona de salida 1: tiene error → sus pesos se modifican.\n",
    "\n",
    "Neuronas de salida 2 y 3: error = 0 → sus deltas son 0 → no modifican sus pesos.\n",
    "\n",
    "Ahora, la capa oculta recibe retropropagación solo desde las conexiones que terminan en neuronas de salida con error.\n",
    "\n",
    "➡️ Como únicamente la salida 1 tuvo error, todos los pesos que van desde las 4 neuronas ocultas hacia la salida 1 se modifican.\n",
    "\n",
    "➡️ A su vez, los pesos que van desde la entrada hacia esas 4 neuronas ocultas también se modifican, porque el error de salida 1 retropropaga hacia ellas.\n",
    "\n",
    "Pesos oculta → salida:\n",
    "\n",
    "4 neuronas ocultas conectadas con la salida 1 → 4 pesos modificados.\n",
    "\n",
    "Pesos entrada → oculta:\n",
    "\n",
    "Cada una de las 4 neuronas ocultas recibe retropropagación desde la salida 1.\n",
    "\n",
    "Si hay 6 entradas, cada oculta tiene 6 pesos.\n",
    "\n",
    "Entonces se modifican \n",
    "$4 + 4⋅n = 28$ pesos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
