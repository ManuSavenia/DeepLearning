{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f5964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FUENTES_DIR = '../Fuentes'         # carpeta donde se encuentran archivos .py auxiliares\n",
    "DATOS_DIR   = '../Data_Sets/p3/' # carpeta donde se encuentran los datasets\n",
    "\n",
    "# agrega ruta de busqueda donde tenemos archivos .py\n",
    "import sys\n",
    "sys.path.append(FUENTES_DIR)\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pylab as plt\n",
    "from IPython import display\n",
    "from ClassPerceptron import Perceptron\n",
    "from sklearn import preprocessing\n",
    "import grafica as gr\n",
    "from ClassNeuronaGral import *\n",
    "from NeuronaSoftMax import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data = pd.read_csv(DATOS_DIR + 'Vinos.csv', sep= ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8396db",
   "metadata": {},
   "source": [
    "## Ejercicio 12\n",
    "\n",
    "Utilice una red neuronal formada por una única capa de salida de 3 neuronas para clasificar las muestras de vino del archivo Vinos.csv descripto en el ejercicio anterior.\n",
    "\n",
    "Realice 30 ejecuciones independientes utilizando el 60% y 80% de los ejemplos como entrenamiento y el resto como testeo.\n",
    "\n",
    "Utilice un máximo de 400 iteraciones y velocidades de aprendizaje 0.1, 0.2 y 0.3.\n",
    "\n",
    "Complete la siguiente tabla con los resultados de las siguientes configuraciones\n",
    "\n",
    "### a) & b)\n",
    "\n",
    "Función de activación ‘sigmoid’ y función de costo ‘ECM’ (error cuadrático medio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f9ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para alpha = 0.1:\n",
      "  Porcentaje entrenamiento 60%:\n",
      "    Accuracy -> Media = 0.9514, Desvío = 0.0205\n",
      "    ECM      -> Media = 0.031823, Desvío = 0.009688\n",
      "    CE bin   -> Media = 0.163252, Desvío = 0.058385\n",
      "  Porcentaje entrenamiento 80%:\n",
      "    Accuracy -> Media = 0.9481, Desvío = 0.0266\n",
      "    ECM      -> Media = 0.029526, Desvío = 0.011668\n",
      "    CE bin   -> Media = 0.147429, Desvío = 0.086654\n",
      "Resultados para alpha = 0.2:\n",
      "  Porcentaje entrenamiento 60%:\n",
      "    Accuracy -> Media = 0.9505, Desvío = 0.0217\n",
      "    ECM      -> Media = 0.033059, Desvío = 0.009412\n",
      "    CE bin   -> Media = 0.174692, Desvío = 0.069746\n",
      "  Porcentaje entrenamiento 80%:\n",
      "    Accuracy -> Media = 0.9472, Desvío = 0.0339\n",
      "    ECM      -> Media = 0.031003, Desvío = 0.016863\n",
      "    CE bin   -> Media = 0.187480, Desvío = 0.147863\n",
      "Resultados para alpha = 0.3:\n",
      "  Porcentaje entrenamiento 60%:\n",
      "    Accuracy -> Media = 0.9505, Desvío = 0.0195\n",
      "    ECM      -> Media = 0.030955, Desvío = 0.008411\n",
      "    CE bin   -> Media = 0.193522, Desvío = 0.075116\n",
      "  Porcentaje entrenamiento 80%:\n",
      "    Accuracy -> Media = 0.9565, Desvío = 0.0384\n",
      "    ECM      -> Media = 0.030542, Desvío = 0.017280\n",
      "    CE bin   -> Media = 0.221736, Desvío = 0.175277\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ejecuciones = 30\n",
    "porcentajes = [0.6, 0.8]\n",
    "alphas = [0.1, 0.2, 0.3]\n",
    "N_ITER = 400\n",
    "COTA = 1e-4\n",
    "scaler = StandardScaler()\n",
    "# Separar atributos y clase\n",
    "X = data.iloc[:, 1:].values          # 13 atributos\n",
    "X = scaler.fit_transform(X)\n",
    "y1 = (data.iloc[:, 0].values == 1).astype(int)  # 1 si es tipo 1, 0 en caso contrario\n",
    "y2 = (data.iloc[:, 0].values == 2).astype(int)  # 1 si es tipo 2, 0 en caso contrario\n",
    "y3 = (data.iloc[:, 0].values == 3).astype(int)  # 1 si es tipo 3, 0 en caso contrario\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "for alpha in alphas:\n",
    "    resultados[alpha] = {}\n",
    "    for p in porcentajes:\n",
    "        resultados[alpha][p] = []\n",
    "        for rep in range(ejecuciones): \n",
    "            # split train / test (en las 3 salidas)\n",
    "            X_train, X_test, y1_train, y1_test, y2_train, y2_test, y3_train, y3_test = train_test_split(\n",
    "                X, y1, y2, y3, train_size=p, shuffle=True\n",
    "            )\n",
    "\n",
    "            # entreno las 3 neuronas (one vs all)\n",
    "            ngs = []\n",
    "            for y_train in [y1_train, y2_train, y3_train]:\n",
    "                ng = NeuronaGradiente(alpha=alpha, n_iter=N_ITER, cotaE=COTA, FUN='sigmoid')\n",
    "                ng.fit(X_train, y_train)\n",
    "                ngs.append(ng)\n",
    "\n",
    "            # ---- PREDICCIÓN ----\n",
    "            # Para cada neurona calculo probabilidad\n",
    "            y1_prob = ngs[0].predict_nOut(X_test)\n",
    "            y2_prob = ngs[1].predict_nOut(X_test)\n",
    "            y3_prob = ngs[2].predict_nOut(X_test)\n",
    "\n",
    "            # Probabilidades de las 3 neuronas\n",
    "            Y_prob = np.column_stack([ngs[0].predict_nOut(X_test),\n",
    "                                      ngs[1].predict_nOut(X_test),\n",
    "                                      ngs[2].predict_nOut(X_test)])\n",
    "            # Clase predicha = la neurona con mayor salida\n",
    "            y_pred = np.argmax(Y_prob, axis=1) + 1\n",
    "\n",
    "            # vector real (1,2,3) a partir de one-hot\n",
    "            y_test_class = np.argmax(np.vstack([y1_test, y2_test, y3_test]).T, axis=1) + 1\n",
    "\n",
    "            # ---- MÉTRICAS ----\n",
    "            accuracy = np.mean(y_pred == y_test_class)\n",
    "\n",
    "            # ECM multiclase\n",
    "            Y_true = np.vstack([y1_test, y2_test, y3_test]).T\n",
    "            ecm = np.mean((Y_prob - Y_true) ** 2)\n",
    "\n",
    "            # Cross Entropy binaria por clase\n",
    "            eps = np.finfo(float).eps\n",
    "            cross_entropy = -np.mean(Y_true * np.log(Y_prob + eps) + (1 - Y_true) * np.log(1 - Y_prob + eps))\n",
    "\n",
    "            resultados[alpha][p].append((accuracy, ecm, cross_entropy)) \n",
    "\n",
    "# impresión de resultados\n",
    "for alpha in alphas:\n",
    "    print(f\"Resultados para alpha = {alpha}:\")\n",
    "    for p in porcentajes:\n",
    "        acc_list  = [acc for acc, _, _ in resultados[alpha][p]]\n",
    "        ecm_list  = [ecm for _, ecm, _ in resultados[alpha][p]]\n",
    "        ce_list   = [ce  for _, _, ce in resultados[alpha][p]]\n",
    "\n",
    "        print(f\"  Porcentaje entrenamiento {int(p*100)}%:\")\n",
    "        print(f\"    Accuracy -> Media = {np.mean(acc_list):.4f}, Desvío = {np.std(acc_list):.4f}\")\n",
    "        print(f\"    ECM      -> Media = {np.mean(ecm_list):.6f}, Desvío = {np.std(ecm_list):.6f}\")\n",
    "        print(f\"    CE bin   -> Media = {np.mean(ce_list):.6f}, Desvío = {np.std(ce_list):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa5513b",
   "metadata": {},
   "source": [
    "### c) \n",
    "\n",
    "Función de activación ‘tanh’ y función de costo ‘ECM’ (error cuadrático medio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11f5c8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para alpha = 0.1:\n",
      "  Porcentaje entrenamiento 60%:\n",
      "    Accuracy -> Media = 0.9486, Desvío = 0.0230\n",
      "    ECM      -> Media = 0.132335, Desvío = 0.045392\n",
      "  Porcentaje entrenamiento 80%:\n",
      "    Accuracy -> Media = 0.9417, Desvío = 0.0315\n",
      "    ECM      -> Media = 0.138357, Desvío = 0.070067\n",
      "Resultados para alpha = 0.2:\n",
      "  Porcentaje entrenamiento 60%:\n",
      "    Accuracy -> Media = 0.9519, Desvío = 0.0151\n",
      "    ECM      -> Media = 0.127380, Desvío = 0.031704\n",
      "  Porcentaje entrenamiento 80%:\n",
      "    Accuracy -> Media = 0.9500, Desvío = 0.0308\n",
      "    ECM      -> Media = 0.119255, Desvío = 0.060887\n",
      "Resultados para alpha = 0.3:\n",
      "  Porcentaje entrenamiento 60%:\n",
      "    Accuracy -> Media = 0.9458, Desvío = 0.0181\n",
      "    ECM      -> Media = 0.134051, Desvío = 0.035531\n",
      "  Porcentaje entrenamiento 80%:\n",
      "    Accuracy -> Media = 0.9472, Desvío = 0.0262\n",
      "    ECM      -> Media = 0.128438, Desvío = 0.061917\n"
     ]
    }
   ],
   "source": [
    "# Separar atributos y clase\n",
    "X = data.iloc[:, 1:].values          # 13 atributos\n",
    "X = scaler.fit_transform(X)\n",
    "y1 = (data.iloc[:, 0].values == 1).astype(int)  # 1 si es tipo 1, 0 en caso contrario\n",
    "y2 = (data.iloc[:, 0].values == 2).astype(int)  # 1 si es tipo 2, 0 en caso contrario\n",
    "y3 = (data.iloc[:, 0].values == 3).astype(int)  # 1 si es tipo 3, 0 en caso contrario\n",
    "\n",
    "#Preparamos las Ys para one-hot \n",
    "y1 = 2 * y1 - 1  # 1 si es tipo 1, -1 en caso contrario\n",
    "y2 = 2 * y2 - 1  # 1 si es tipo 2, -1 en caso contrario\n",
    "y3 = 2 * y3 - 1  # 1 si es tipo 3, -1 en caso contrario\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "for alpha in alphas:\n",
    "    resultados[alpha] = {}\n",
    "    for p in porcentajes:\n",
    "        resultados[alpha][p] = []\n",
    "        for rep in range(ejecuciones): \n",
    "            # split train / test (en las 3 salidas)\n",
    "            X_train, X_test, y1_train, y1_test, y2_train, y2_test, y3_train, y3_test = train_test_split(\n",
    "                X, y1, y2, y3, train_size=p, shuffle=True\n",
    "            )\n",
    "\n",
    "            # entreno las 3 neuronas (one vs all)\n",
    "            ngs = []\n",
    "            for y_train in [y1_train, y2_train, y3_train]:\n",
    "                ng = NeuronaGradiente(alpha=alpha, n_iter=N_ITER, cotaE=COTA, FUN='tanh')\n",
    "                ng.fit(X_train, y_train)\n",
    "                ngs.append(ng)\n",
    "\n",
    "            # ---- PREDICCIÓN ----\n",
    "            # Para cada neurona calculo probabilidad\n",
    "            y1_prob = ngs[0].predict_nOut(X_test)\n",
    "            y2_prob = ngs[1].predict_nOut(X_test)\n",
    "            y3_prob = ngs[2].predict_nOut(X_test)\n",
    "\n",
    "            # Probabilidades de las 3 neuronas\n",
    "            Y_prob = np.column_stack([ngs[0].predict_nOut(X_test),\n",
    "                                      ngs[1].predict_nOut(X_test),\n",
    "                                      ngs[2].predict_nOut(X_test)])\n",
    "            # Clase predicha = la neurona con mayor salida\n",
    "            y_pred = np.argmax(Y_prob, axis=1) + 1\n",
    "\n",
    "            # vector real (1,2,3) a partir de one-hot\n",
    "            y_test_class = np.argmax(np.vstack([y1_test, y2_test, y3_test]).T, axis=1) + 1\n",
    "\n",
    "            # ---- MÉTRICAS ----\n",
    "            accuracy = np.mean(y_pred == y_test_class)\n",
    "\n",
    "            # ECM multiclase\n",
    "            Y_true = np.vstack([y1_test, y2_test, y3_test]).T\n",
    "            ecm = np.mean((Y_prob - Y_true) ** 2)\n",
    "\n",
    "            resultados[alpha][p].append((accuracy, ecm)) \n",
    "\n",
    "# impresión de resultados\n",
    "for alpha in alphas:\n",
    "    print(f\"Resultados para alpha = {alpha}:\")\n",
    "    for p in porcentajes:\n",
    "        acc_list  = [acc for acc, _ in resultados[alpha][p]]\n",
    "        ecm_list  = [ecm for _, ecm, in resultados[alpha][p]]\n",
    "\n",
    "        print(f\"  Porcentaje entrenamiento {int(p*100)}%:\")\n",
    "        print(f\"    Accuracy -> Media = {np.mean(acc_list):.4f}, Desvío = {np.std(acc_list):.4f}\")\n",
    "        print(f\"    ECM      -> Media = {np.mean(ecm_list):.6f}, Desvío = {np.std(ecm_list):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e5959d",
   "metadata": {},
   "source": [
    "### d) \n",
    "\n",
    "Capa ‘Softmax’ y función de costo ‘EC’ (entropía cruzada).\n",
    "\n",
    "Pdt:(esto son 3 neuronas con gradiente binario, no una red multiclase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397feb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para alpha = 0.1:\n",
      "  Porcentaje entrenamiento 60%:\n",
      "    Accuracy -> Media = 0.9458, Desvío = 0.0249\n",
      "    ECM      -> Media = 0.105875, Desvío = 0.005730\n",
      "    CE bin   -> Media = 0.615922, Desvío = 0.022788\n",
      "  Porcentaje entrenamiento 80%:\n",
      "    Accuracy -> Media = 0.9565, Desvío = 0.0318\n",
      "    ECM      -> Media = 0.104318, Desvío = 0.006572\n",
      "    CE bin   -> Media = 0.610006, Desvío = 0.026797\n",
      "Resultados para alpha = 0.2:\n",
      "  Porcentaje entrenamiento 60%:\n",
      "    Accuracy -> Media = 0.9528, Desvío = 0.0198\n",
      "    ECM      -> Media = 0.103760, Desvío = 0.003659\n",
      "    CE bin   -> Media = 0.607327, Desvío = 0.014812\n",
      "  Porcentaje entrenamiento 80%:\n",
      "    Accuracy -> Media = 0.9611, Desvío = 0.0283\n",
      "    ECM      -> Media = 0.102749, Desvío = 0.006230\n",
      "    CE bin   -> Media = 0.603494, Desvío = 0.025172\n",
      "Resultados para alpha = 0.3:\n",
      "  Porcentaje entrenamiento 60%:\n",
      "    Accuracy -> Media = 0.9542, Desvío = 0.0183\n",
      "    ECM      -> Media = 0.103952, Desvío = 0.003778\n",
      "    CE bin   -> Media = 0.608524, Desvío = 0.015599\n",
      "  Porcentaje entrenamiento 80%:\n",
      "    Accuracy -> Media = 0.9537, Desvío = 0.0307\n",
      "    ECM      -> Media = 0.102816, Desvío = 0.005357\n",
      "    CE bin   -> Media = 0.603772, Desvío = 0.021947\n"
     ]
    }
   ],
   "source": [
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  # estabilidad numérica\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "# Separar atributos y clase\n",
    "X = data.iloc[:, 1:].values          # 13 atributos\n",
    "X = scaler.fit_transform(X)\n",
    "y1 = (data.iloc[:, 0].values == 1).astype(int)  # 1 si es tipo 1, 0 en caso contrario\n",
    "y2 = (data.iloc[:, 0].values == 2).astype(int)  # 1 si es tipo 2, 0 en caso contrario\n",
    "y3 = (data.iloc[:, 0].values == 3).astype(int)  # 1 si es tipo 3, 0 en caso contrario\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "for alpha in alphas:\n",
    "    resultados[alpha] = {}\n",
    "    for p in porcentajes:\n",
    "        resultados[alpha][p] = []\n",
    "        for rep in range(ejecuciones): \n",
    "            # split train / test (en las 3 salidas)\n",
    "            X_train, X_test, y1_train, y1_test, y2_train, y2_test, y3_train, y3_test = train_test_split(\n",
    "                X, y1, y2, y3, train_size=p, shuffle=True\n",
    "            )\n",
    "\n",
    "            # entreno las 3 neuronas (one vs all)\n",
    "            ngs = []\n",
    "            for y_train in [y1_train, y2_train, y3_train]:\n",
    "                ng = NeuronaGradiente(alpha=alpha, n_iter=N_ITER, cotaE=COTA, FUN='sigmoid')\n",
    "                ng.fit(X_train, y_train)\n",
    "                ngs.append(ng)\n",
    "\n",
    "            # ---- PREDICCIÓN ----\n",
    "            # Obtener salidas crudas (antes del softmax)\n",
    "            Y_raw = np.column_stack([\n",
    "                ngs[0].predict_nOut(X_test),\n",
    "                ngs[1].predict_nOut(X_test),\n",
    "                ngs[2].predict_nOut(X_test)\n",
    "            ])\n",
    "\n",
    "            # Aplicar softmax a las 3 neuronas\n",
    "            Y_prob = softmax(Y_raw)\n",
    "\n",
    "            # Clase predicha = argmax de la probabilidad softmax\n",
    "            y_pred = np.argmax(Y_prob, axis=1) + 1\n",
    "\n",
    "            # vector real (1,2,3) a partir de one-hot\n",
    "            y_test_class = np.argmax(np.vstack([y1_test, y2_test, y3_test]).T, axis=1) + 1\n",
    "\n",
    "            # ---- MÉTRICAS ----\n",
    "            accuracy = np.mean(y_pred == y_test_class)\n",
    "\n",
    "            # ECM multiclase\n",
    "            Y_true = np.vstack([y1_test, y2_test, y3_test]).T\n",
    "            ecm = np.mean((Y_prob - Y_true) ** 2)\n",
    "\n",
    "            # Entropía cruzada multiclase (categorical CE)\n",
    "            eps = np.finfo(float).eps\n",
    "            cross_entropy = -np.mean(np.sum(Y_true * np.log(Y_prob + eps), axis=1))\n",
    "\n",
    "            resultados[alpha][p].append((accuracy, ecm, cross_entropy)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# impresión de resultados\n",
    "for alpha in alphas:\n",
    "    print(f\"Resultados para alpha = {alpha}:\")\n",
    "    for p in porcentajes:\n",
    "        acc_list  = [acc for acc, _, _ in resultados[alpha][p]]\n",
    "        ecm_list  = [ecm for _, ecm, _ in resultados[alpha][p]]\n",
    "        ce_list   = [ce  for _, _, ce in resultados[alpha][p]]\n",
    "\n",
    "        print(f\"  Porcentaje entrenamiento {int(p*100)}%:\")\n",
    "        print(f\"    Accuracy -> Media = {np.mean(acc_list):.4f}, Desvío = {np.std(acc_list):.4f}\")\n",
    "        print(f\"    ECM      -> Media = {np.mean(ecm_list):.6f}, Desvío = {np.std(ecm_list):.6f}\")\n",
    "        print(f\"    CE    -> Media = {np.mean(ce_list):.6f}, Desvío = {np.std(ce_list):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c90a117",
   "metadata": {},
   "source": [
    "Prueba con cross-entropy categórica (no binaria)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8ce78a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados para alpha = 0.1:\n",
      "  Porcentaje entrenamiento 60%:\n",
      "    Accuracy -> Media = 0.9361, Desvío = 0.0198\n",
      "    ECM      -> Media = 0.032705, Desvío = 0.007132\n",
      "    CE cat   -> Media = 0.289365, Desvío = 0.055233\n",
      "  Porcentaje entrenamiento 80%:\n",
      "    Accuracy -> Media = 0.9500, Desvío = 0.0272\n",
      "    ECM      -> Media = 0.022269, Desvío = 0.011616\n",
      "    CE cat   -> Media = 0.136798, Desvío = 0.086729\n",
      "\n",
      "Resultados para alpha = 0.2:\n",
      "  Porcentaje entrenamiento 60%:\n",
      "    Accuracy -> Media = 0.9292, Desvío = 0.0313\n",
      "    ECM      -> Media = 0.035851, Desvío = 0.011316\n",
      "    CE cat   -> Media = 0.278094, Desvío = 0.127218\n",
      "  Porcentaje entrenamiento 80%:\n",
      "    Accuracy -> Media = 0.9472, Desvío = 0.0262\n",
      "    ECM      -> Media = 0.029554, Desvío = 0.014118\n",
      "    CE cat   -> Media = 0.281098, Desvío = 0.250956\n",
      "\n",
      "Resultados para alpha = 0.3:\n",
      "  Porcentaje entrenamiento 60%:\n",
      "    Accuracy -> Media = 0.9208, Desvío = 0.0335\n",
      "    ECM      -> Media = 0.041438, Desvío = 0.017609\n",
      "    CE cat   -> Media = 0.323382, Desvío = 0.136739\n",
      "  Porcentaje entrenamiento 80%:\n",
      "    Accuracy -> Media = 0.9167, Desvío = 0.0351\n",
      "    ECM      -> Media = 0.046174, Desvío = 0.020235\n",
      "    CE cat   -> Media = 0.411125, Desvío = 0.254447\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values - 1   # clases 0,1,2\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# One-hot encoding\n",
    "Y = np.zeros((len(y), 3))\n",
    "Y[np.arange(len(y)), y] = 1\n",
    "\n",
    "# ---------- Experimentos ----------\n",
    "alphas = [0.1, 0.2, 0.3]\n",
    "porcentajes = [0.6, 0.8]\n",
    "ejecuciones = 10\n",
    "N_ITER = 2000\n",
    "COTA = 1e-5\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "for alpha in alphas:\n",
    "    resultados[alpha] = {}\n",
    "    for p in porcentajes:\n",
    "        accs, ecs, ces = [], [], []\n",
    "        for _ in range(ejecuciones):\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=p, shuffle=True)\n",
    "\n",
    "            ng = NeuronaSoftmax(alpha=alpha, n_iter=N_ITER, cotaE=COTA)\n",
    "            ng.fit(X_train, Y_train)\n",
    "\n",
    "            Y_prob = ng.predict_proba(X_test)\n",
    "            y_pred = np.argmax(Y_prob, axis=1)\n",
    "            y_true = np.argmax(Y_test, axis=1)\n",
    "\n",
    "            # Accuracy\n",
    "            acc = np.mean(y_pred == y_true)\n",
    "\n",
    "            # ECM\n",
    "            ecm = np.mean((Y_prob - Y_test) ** 2)\n",
    "\n",
    "            # Cross entropy categórica\n",
    "            ce = -np.mean(np.sum(Y_test * np.log(Y_prob + 1e-15), axis=1))\n",
    "\n",
    "            accs.append(acc)\n",
    "            ecs.append(ecm)\n",
    "            ces.append(ce)\n",
    "\n",
    "        resultados[alpha][p] = (np.mean(accs), np.std(accs),\n",
    "                                np.mean(ecs), np.std(ecs),\n",
    "                                np.mean(ces), np.std(ces))\n",
    "\n",
    "\n",
    "# ---------- Resultados ----------\n",
    "for alpha in alphas:\n",
    "    print(f\"\\nResultados para alpha = {alpha}:\")\n",
    "    for p in porcentajes:\n",
    "        acc_mean, acc_std, ecm_mean, ecm_std, ce_mean, ce_std = resultados[alpha][p]\n",
    "        print(f\"  Porcentaje entrenamiento {int(p*100)}%:\")\n",
    "        print(f\"    Accuracy -> Media = {acc_mean:.4f}, Desvío = {acc_std:.4f}\")\n",
    "        print(f\"    ECM      -> Media = {ecm_mean:.6f}, Desvío = {ecm_std:.6f}\")\n",
    "        print(f\"    CE cat   -> Media = {ce_mean:.6f}, Desvío = {ce_std:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
