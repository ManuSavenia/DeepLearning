{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd07b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "FUENTES_DIR = '../Fuentes'         # carpeta donde se encuentran archivos .py auxiliares\n",
    "DATOS_DIR   = '../Data_Sets/p2/' # carpeta donde se encuentran los datasets\n",
    "\n",
    "# agrega ruta de busqueda donde tenemos archivos .py\n",
    "import sys\n",
    "sys.path.append(FUENTES_DIR)\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pylab as plt\n",
    "from IPython import display\n",
    "from ClassPerceptron import Perceptron\n",
    "from sklearn import preprocessing\n",
    "import grafica as gr\n",
    "from ClassNeuronaLineal import NeuronaLineal\n",
    "from ClassNeuronaGral import *\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaca78e",
   "metadata": {},
   "source": [
    "# Regresión Lineal Múltiple (dos o más variables de entrada)\n",
    "\n",
    "## Ejercicio 6\n",
    "\n",
    "Utilice los scripts disponibles en la teoría y práctica para entrenar un combinador lineal.  \n",
    "El modelo debe recibir tres dígitos binarios y retornar la representación decimal del número que resulta de la combinación de dígitos (para las entradas 000, 010 y 101 debe obtener las salidas 0, 2 y 5, respectivamente).\n",
    "\n",
    "a) Utilizando el bias o peso W0 (comportamiento normal).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed2ebbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pesos aprendidos: [3.99492129 1.99474855 0.99475783]\n",
      "Bias: 0.01123937330818493\n",
      "[0 0 0] -> pred: 0.01, esperado: 0\n",
      "[0 0 1] -> pred: 1.01, esperado: 1\n",
      "[0 1 0] -> pred: 2.01, esperado: 2\n",
      "[0 1 1] -> pred: 3.00, esperado: 3\n",
      "[1 0 0] -> pred: 4.01, esperado: 4\n",
      "[1 0 1] -> pred: 5.00, esperado: 5\n",
      "[1 1 0] -> pred: 6.00, esperado: 6\n",
      "[1 1 1] -> pred: 7.00, esperado: 7\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    \"Binarios\": [(0,0,0), (0,0,1), (0,1,0), (0,1,1), (1,0,0), (1,0,1), (1,1,0), (1,1,1)],\n",
    "    \"Decimal\": [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "})\n",
    "ALPHA = 0.1\n",
    "N_ITER = 1000\n",
    "COTA_E = 1e-4\n",
    "\n",
    "X = np.array(data[\"Binarios\"].to_list())\n",
    "y = np.array(data[\"Decimal\"])\n",
    "\n",
    "modelo = NeuronaLineal(alpha=ALPHA, n_iter=N_ITER, cotaE=COTA_E, draw=1,\n",
    "                       title=['Binario', 'Decimal'])\n",
    "modelo.fit(X, y)\n",
    "print(\"\\nPesos aprendidos:\", modelo.w_)\n",
    "print(\"Bias:\", modelo.b_)\n",
    "\n",
    "# Test\n",
    "for xi, target in zip(X, y):\n",
    "    print(f\"{xi} -> pred: {modelo.predict(xi):.2f}, esperado: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f98acf",
   "metadata": {},
   "source": [
    "### b) \n",
    "\n",
    "Utilizando únicamente las tres entradas correspondientes a los dígitos binarios anulando el bias o W0 del cálculo.  \n",
    "\n",
    "Compare la cantidad de iteraciones necesarias para obtener el vector de pesos correcto en ambos casos. Observe el valor del arco correspondiente al bias en a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c5a9841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio sin bias:  0.33813789609063716\n",
      "Iteraciones sin bias: 84\n",
      "Valor del arco del bias:  0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "ALPHA = 0.05\n",
    "MAX_ITE = 10000\n",
    "COTA = 10e-6\n",
    "\n",
    "X = np.array([[0,0,0],\n",
    "\t\t\t[0,1,0],\n",
    "\t\t\t[1,0,1]])\n",
    "\n",
    "T = np.array([[0],\n",
    "\t\t\t[2],\n",
    "\t\t\t[5]])\n",
    "\n",
    "data_scaler , targer_scaler= MinMaxScaler(), MinMaxScaler()\n",
    "X = data_scaler.fit_transform(X)\n",
    "T = targer_scaler.fit_transform(T)\n",
    "\n",
    "\n",
    "ng_no_bias = NeuronaGradiente(alpha=ALPHA, n_iter=MAX_ITE, cotaE=COTA, FUN='linear', title=['bits','decimal'], with_bias=False)\n",
    "\n",
    "ng_no_bias.fit(X, T)\n",
    "\n",
    "Y_pred = ng_no_bias.predict_nOut(X)\n",
    "print(\"Error cuadrático medio sin bias: \", np.mean((T - Y_pred)**2))\n",
    "print(\"Iteraciones sin bias:\", ng_no_bias.iterations_)\n",
    "print(\"Valor del arco del bias: \", ng_no_bias.b_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
